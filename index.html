<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Wanek, Woodny Dorceans">
<meta name="dcterms.date" content="2023-07-09">

<title>Stocks K-Means Clustering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Stocks K-Means Clustering</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Michael Wanek, Woodny Dorceans </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 9, 2023</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="literature-review" class="level2">
<h2 class="anchored" data-anchor-id="literature-review">Literature Review</h2>
<p>The k-means clustering algorithm is an unsupervised machine learning algorithm due to its used of grouping similar unlabelled data points into groups. one of the article review focuses on four of the k value, such as the elbow method, gap statistic, silhouette coefficient, and canopy. The k-value method which stood out is the silhouette coefficient one, which looks at the cohesiveness between the cluster. The article then used the Iris dataset to provide evidence of their experiment. They applied the mentioned four k value algorithm and evaluated the results. Based on the results, the canopy was less effective when choosing the k value. This article also provides the different advantages of the four algorithms. After clustering the data, supervised learning can potentially take place. For example, the Euclidean distance uses the Pythagorean theorem; however, not only in two dimensions, but with as many dimensions as needed. However, when the dimensions are very high, the Cosine method works better. The Cosine method is the cosine of the angle between any two points with the origin at its vertex. It is then calculated by dividing the dot product of any two vectors by the product of the vector magnitudes. The Manhattan distance measures the right angle along the “x” and “y” axis. This is essentially the sum of the absolute value of the differences between two coordinates. The Hamming distance takes into consideration the number of coordinates differing from each other. The textbook discusses how “R” is used in the context of K-means clustering. There are several steps involved including random coordinates on the scatterplot as the initial cluster centers named “k1” and “k2” for a two-cluster analysis. Next, the number of iterations needs to be determined such that the centers of the data stop changing significantly after each iteration. Then the Euclidean distance, if that is the selected methodology, will be used by applying the square root function as “sqrt()” in R. Each point must be assigned to the cluster whose center it is closest to. Then, the mean function, “mean()”, can be used to obtain the mean x and y coordinates of the points for each cluster. Another scatterplot can be used to visually identify clusters using different colors. From there, one can determine if the algorithm was successful in generating a useful analysis.</p>
<p>K-means clustering (KMC) is an algorithm that can be used for potentially maximizing profit, or reducing risk, when investing in company stock (Soofi et al., 2015). Using KMC, stock data can be grouped together in accordance with predetermined criteria to find similarity, dissimilarity, and structure. One can consider ‘crisp clusters’ where data belongs to only one cluster, or ‘fuzzy clustering’ where data can belong to more than one cluster. Clustering algorithms, such as the k-means clustering (KMC) algorithm, have gained attention as valuable tools for aiding investment decision-making. One of the articles reviewed proposed resolution for the fact that there is a need for better initial centroids, and the way to do so is by sorting the data points distance-wise and separating them into equal sets. The authors believe partitioning the data in a sorted method leads to better results. The authors then reassign the data points to the correct clusters by looking at the distance between the centroid to whichever cluster is closest. We also see in this article that the authors address the time complexity involved with k-means clustering. The proposed method uses a heap sort method, which is O(nlogn); combining that with the time complexity, we still see that time complexity is O(nlogn) on average. This confirms that the proposed method in this article is more efficient than the original k-means clustering. The experimental results also corroborate this. The articles provides an overview of KMC, challenges/limitations of the algorithm, and analysis of stocks using k-means with the results. The articles reviewed explore various aspects, including data selection, methodology, optimization techniques, and the impact of different factors on stock prices.</p>
<p>Through the use of data mining technology, large amounts of complex financial data can be analyzed. KMC can be used to classify financial features according to maximum and minimum similarity. However, there are some shortcomings to the method including the determination of the number of ‘k clusters’, different distance calculation methods, and the problem of local extremum. The study utilized the ‘artificial fish swarm algorithm’ to correct for these shortcomings. The data included 100 financial companies analyzing the following data: closing price, price earnings ratio, earnings-per-share, return on net assets, per share provident fund, and net assets per share. The data that was extracted with relation to KMC included the convergence time, standard deviation, and silhouette coefficient. The silhouette coefficient for this dataset was 0.63 and results that are close to 1 demonstrate better clustering performance. Additionally, the stock clustering results were placed into 2 categories: poor performance versus high-performance stock. In general, stocks that were deemed high-performance had significantly higher closing prices, higher price earnings ratios, high earnings-per-share, and high return on net assets. The paper demonstrated that the classification of stocks could assist investors in making selections improving investment performance. This journal article analyzed the monthly rate of return of banks using the K-means clustering algorithm. Specifically, a clustering approach was used to understand and identify stock market price movement patterns as a result of macro economic indicators. Simultaneously, the clustering method was used to provide a perspective on optimizing investment returns with respect to the banking sector. The data that was analyzed included monthly prices on the stock market index of the banking sector in Indonesia, the reference rate from the Central Bank of Indonesia, the US dollar to the rupiah exchange rate, the inflation rate, and the consumer price index. By using the K-means clustering method, the goal was to find homogeneous subgroups within the data whose points were as close as possible according to each cluster. This was accomplished by using that Euclidean distance thereby minimizing the paired squared deviations of points within the same cluster. In this case, three clusters were determined based on the average rate of return as follows: lower, middle, and upper. The analysis found that the cluster centers were located at 0.010, 0.014, and 0.178. Also, it was found that interest rates negatively affected the stock prices. Additionally, strengthening of the US dollar against the rupiah increased the banking stocks in the middle upper cluster. With respect to inflation, it negatively impacted the lower cluster, and insignificant impact on the middle cluster, and a positive impact on the upper cluster. As a result, the study concluded that the K-means clustering method can assist in optimizing returns considering each analyzed cluster. In essence, the middle cluster was more reactive with respect to interest and exchange rates, and the upper cluster was reactive to inflation.</p>
<p>The article looked at different methods, starting with classification, prediction, and clustering. When looking at classification, it defines the classes by using models. The classification is then used to predict any data that is not available or for missing values. The article then touches on the challenges with classification. The k-means cluster in this article was used to create sub-clusters and leveraged purity thresholds to prevent problems. Reviewing the effectiveness of the cluster method, companies were grouped based on information from their annual financial reports. Based on the results, the best information to help predict future stock prices was found using their qualitative piece of the annual report. The author proposes a method to see which companies are more profitable, which would lead to purchasing the best stock. The article does look at different types of techniques and research completed by others. The authors reviewed the portioning, density-based, hierarchical, and model-based techniques which were then validated by using the index of each technique. As a result of those validations, the partitioning based on k-means and model-based techniques performed the best. The authors also combine regression methods to the predictive piece of the model. Once the authors determined the companies based on the clustering technique, they used the regression method to predict future stock prices. This article does help both buyers and sellers with their prediction since their method will tell buyers the best time to get in the market before a price increase and, in turn, tell sellers to either hold or sell if prices will be lowered. In the article, we also saw results for the TCS company, which shows the stock price doubling in the future.</p>
<p>The final article explained the problem of stock market investors who make psychologically-based or cognitively biased decisions when making stock picks. As part of the analysis, K-means clustering was used to separate investor groups into their behaviors using the subgroups of market experience, invested amount, age, and market perception. This was performed using the “R” software analysis tool. As an additional tool to assist in creating the clusters of data, the silhouette statistic was used to determine if the centroid of the clusters were of appropriate distance. The K-means clusters were visualized in two-dimensional space which helped determine the optimal number of clusters as k=3. The Euclidean distance was used for this K-means clustering method. The cluster groups were as follows: 1. confirmation bias and investment amount; 2. age, gender, and economic assessment; 3. biases such as bandwagon, billability, loss aversion, hot hand, gamblers, and Dunning-Kruger combined with investment experience. It was found that loss aversion bias, experience, and gamblers bias were the greatest influential factors. The least influential factors were age, gender, and perception of economy. However, other statistical tests that were utilized in this study found that age was a significant factor in risk-taking. Therefore, from an empirical perspective, multiple methods should be used to help discern how bias affects investment decision-making in the stock market.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<p>$$</p>
<p>$$</p>
<div class="cell">

</div>
<div class="cell">

</div>
<section id="analysis-and-results" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-results">Analysis and Results</h3>
</section>
<section id="statistical-modeling" class="level3">
<h3 class="anchored" data-anchor-id="statistical-modeling">Statistical Modeling</h3>
</section>
<section id="conlusion" class="level3">
<h3 class="anchored" data-anchor-id="conlusion">Conlusion</h3>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>Ahmed, M., Seraj, R., &amp; Islam, S. M. S. (2020). The k-means algorithm: A comprehensive survey and performance evaluation. Electronics, 9(8), 1295.</p>
<p>Babu, M. S., Geethanjali, N., &amp; Satyanarayana, B. (2012). Clustering approach to stock market prediction. International Journal of Advanced Networking and Applications, 3(4), 1281.</p>
<p>Bini, B. S., &amp; Mathew, T. (2016). Clustering and regression techniques for stock prediction. Procedia Technology, 24, 1248-1255.</p>
<p>Fang, &amp; Chiao, C. (2021). Research on prediction and recommendation of financial stocks based on K-means clustering algorithm optimization. Journal of Computational Methods in Sciences and Engineering, 21(5), 1081–1089. https://doi.org/10.3233/JCM-204716</p>
<p>Malik, &amp; Tuckfield, B. (2019). Applied unsupervised learning with R: Uncover hidden relationships and patterns with K-Means clustering, hierarchical clustering, and PCA (1st edition). Packt Publishing Ltd.</p>
<p>Ossareh, Pourjafar, M. S., &amp; Kopczewski, T. (2021). Cognitive Biases on the Iran Stock Exchange: Unsupervised Learning Approach to Examining Feature Bundles in Investors’ Portfolios. Applied Sciences, 11(22), 10916–. https://doi.org/10.3390/app112210916</p>
<p>Soofi , Mohseni , M., &amp; Momeni , M. (2015). Clustering Stock Market Companies via K- Means Algorithm. Kuwait Chapter of Arabian Journal of Business &amp; Management Review, 4(5), 1–10. https://doi.org/10.12816/0018959</p>
<p>Yedla, M., Pathakota, S. R., &amp; Srinivasa, T. M. (2010). Enhancing K-means clustering algorithm with improved initial center. International Journal of computer science and information technologies, 1(2), 121-125.</p>
<p>Yuan, C., &amp; Yang, H. (2019). Research on K-value selection method of K-means clustering algorithm. J, 2(2), 226-235.</p>
<p>Zuhroh, Rofik, M., &amp; Echchabi, A. (2021). Banking stock price movement and macroeconomic indicators: k-means clustering approach. Cogent Business &amp; Management, 8(1), 1–10. https://doi.org/10.1080/23311975.2021.1980247</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>